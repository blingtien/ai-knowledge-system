#!/usr/bin/env python3
"""
AIçŸ¥è¯†ç®¡ç†ç³»ç»ŸæœåŠ¡ç®¡ç†å™¨
æ”¯æŒæœåŠ¡å¯åŠ¨ã€åœæ­¢ã€ç›‘æ§å’Œèµ„æºç®¡ç†
"""
import os
import sys
import yaml
import json
import time
import signal
import psutil
import subprocess
import threading
from pathlib import Path
from datetime import datetime
import argparse


class ServiceManager:
    def __init__(self, base_dir="~/ai-knowledge-system"):
        self.base_dir = Path(base_dir).expanduser()
        self.configs_dir = self.base_dir / "configs"
        self.environments_dir = self.base_dir / "environments"
        self.services_dir = self.base_dir / "services"
        self.logs_dir = self.base_dir / "logs"
        self.state_file = self.base_dir / "services_state.json"

        # åˆ›å»ºå¿…è¦ç›®å½•
        for dir_path in [self.services_dir, self.logs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        self.load_state()

    def load_env_file(self):
        """åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡"""
        env_vars = {}
        env_file = self.base_dir / ".env"

        if not env_file.exists():
            print(f"âš ï¸ ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {env_file}")
            return env_vars

        print(f"ğŸ”„ åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
        loaded_count = 0

        with open(env_file, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    try:
                        key, value = line.split("=", 1)
                        key = key.strip()
                        value = value.strip().strip('"').strip("'")
                        env_vars[key] = value
                        loaded_count += 1

                        if (
                            key == "OPENAI_API_KEY"
                            and value != "your_openai_api_key_here"
                        ):
                            print(f"âœ“ APIå¯†é’¥å·²åŠ è½½: {value[:10]}...{value[-4:]}")
                    except ValueError:
                        print(f"âš ï¸ ç¬¬{line_num}è¡Œæ ¼å¼é”™è¯¯: {line}")
                        continue

        print(f"âœ“ ä».envæ–‡ä»¶åŠ è½½äº† {loaded_count} ä¸ªç¯å¢ƒå˜é‡")
        return env_vars

    def load_state(self):
        """åŠ è½½æœåŠ¡çŠ¶æ€"""
        if self.state_file.exists():
            with open(self.state_file, "r") as f:
                self.state = json.load(f)
        else:
            self.state = {"services": {}}
            self.save_state()

    def save_state(self):
        """ä¿å­˜æœåŠ¡çŠ¶æ€"""
        with open(self.state_file, "w") as f:
            json.dump(self.state, f, indent=2)

    def load_service_config(self, service_name):
        """åŠ è½½æœåŠ¡é…ç½®"""
        # å°è¯•æ–°çš„å‘½åæ–¹å¼
        config_file = self.configs_dir / f"{service_name}_service_config.yaml"
        if not config_file.exists():
            # å°è¯•æ—§çš„å‘½åæ–¹å¼
            config_file = self.configs_dir / f"{service_name}_config.yaml"

        if not config_file.exists():
            raise ValueError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

        with open(config_file, "r") as f:
            return yaml.safe_load(f)

    def start_service(self, service_name):
        """å¯åŠ¨æœåŠ¡"""
        if self.is_service_running(service_name):
            print(f"æœåŠ¡ {service_name} å·²åœ¨è¿è¡Œ")
            return

        try:
            config = self.load_service_config(service_name)
            env_name = config["environment"]
            env_path = self.environments_dir / env_name

            if not env_path.exists():
                raise ValueError(f"è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨: {env_path}")

            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env["PYTHONPATH"] = str(self.base_dir)

            # åŠ è½½.envæ–‡ä»¶ - å…³é”®ä¿®å¤
            env_vars = self.load_env_file()
            env.update(env_vars)  # å°†.envæ–‡ä»¶ä¸­çš„å˜é‡åˆå¹¶åˆ°ç¯å¢ƒä¸­

            # éªŒè¯APIå¯†é’¥ - å¢å¼ºéªŒè¯
            api_key = env.get("OPENAI_API_KEY")
            if not api_key or api_key == "your_openai_api_key_here":
                print("âŒ é”™è¯¯: OPENAI_API_KEYæœªè®¾ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")
                print(f"è¯·ç¼–è¾‘ {self.base_dir}/.env æ–‡ä»¶è®¾ç½®æ­£ç¡®çš„APIå¯†é’¥")
                return False
            else:
                print(f"âœ“ APIå¯†é’¥éªŒè¯é€šè¿‡: {api_key[:10]}...{api_key[-4:]}")

            # å¯åŠ¨æœåŠ¡
            service_script = self.services_dir / f"{service_name}.py"
            if not service_script.exists():
                self.create_service_script(service_name, config)

            python_path = env_path / "bin" / "python"
            log_file = self.logs_dir / f"{service_name}.log"

            print(f"ğŸš€ å¯åŠ¨æœåŠ¡ {service_name}...")
            with open(log_file, "a") as log:
                log.write(f"\n=== æœåŠ¡å¯åŠ¨ {datetime.now().isoformat()} ===\n")
                process = subprocess.Popen(
                    [str(python_path), str(service_script)],
                    env=env,
                    stdout=log,
                    stderr=log,
                )

            # ç­‰å¾…æœåŠ¡å¯åŠ¨
            timeout = config.get("startup_timeout", 30)
            if self.wait_for_service_health(service_name, config, timeout):
                self.state["services"][service_name] = {
                    "pid": process.pid,
                    "port": config["port"],
                    "started_at": datetime.now().isoformat(),
                    "status": "running",
                    "config": config,
                }
                self.save_state()
                print(
                    f"âœ… æœåŠ¡ {service_name} å¯åŠ¨æˆåŠŸ (PID: {process.pid}, ç«¯å£: {config['port']})"
                )
                return True
            else:
                process.terminate()
                print(f"âŒ æœåŠ¡ {service_name} å¯åŠ¨å¤±è´¥ - å¥åº·æ£€æŸ¥è¶…æ—¶")

                # æ˜¾ç¤ºæœ€åå‡ è¡Œæ—¥å¿—
                if log_file.exists():
                    print("æœ€å10è¡Œæ—¥å¿—:")
                    try:
                        subprocess.run(["tail", "-10", str(log_file)])
                    except:
                        # å¦‚æœtailå‘½ä»¤ä¸å¯ç”¨ï¼Œæ‰‹åŠ¨è¯»å–
                        with open(log_file, "r") as f:
                            lines = f.readlines()
                            for line in lines[-10:]:
                                print(line.strip())
                return False

        except Exception as e:
            print(f"âŒ å¯åŠ¨æœåŠ¡ {service_name} å¤±è´¥: {e}")
            return False

    def stop_service(self, service_name):
        """åœæ­¢æœåŠ¡"""
        if service_name not in self.state["services"]:
            print(f"æœåŠ¡ {service_name} æœªè¿è¡Œ")
            return

        service_info = self.state["services"][service_name]
        pid = service_info["pid"]

        try:
            if psutil.pid_exists(pid):
                process = psutil.Process(pid)
                process.terminate()

                # ç­‰å¾…è¿›ç¨‹ç»“æŸ
                try:
                    process.wait(timeout=10)
                    print(f"âœ… æœåŠ¡ {service_name} åœæ­¢æˆåŠŸ")
                except psutil.TimeoutExpired:
                    process.kill()
                    print(f"âœ… æœåŠ¡ {service_name} å¼ºåˆ¶åœæ­¢")

            del self.state["services"][service_name]
            self.save_state()

        except Exception as e:
            print(f"âŒ åœæ­¢æœåŠ¡ {service_name} å¤±è´¥: {e}")

    def is_service_running(self, service_name):
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ"""
        if service_name not in self.state["services"]:
            return False

        pid = self.state["services"][service_name]["pid"]
        return psutil.pid_exists(pid)

    def wait_for_service_health(self, service_name, config, timeout):
        """ç­‰å¾…æœåŠ¡å¥åº·æ£€æŸ¥"""
        import requests

        port = config["port"]
        health_endpoint = config.get("health_endpoint", "/health")
        url = f"http://localhost:{port}{health_endpoint}"

        print(f"â³ ç­‰å¾…æœåŠ¡å¥åº·æ£€æŸ¥: {url}")
        for i in range(timeout):
            try:
                response = requests.get(url, timeout=2)
                if response.status_code == 200:
                    print(f"âœ… å¥åº·æ£€æŸ¥é€šè¿‡ ({i+1}s)")
                    return True
            except:
                pass

            if i % 5 == 0 and i > 0:
                print(f"  â³ ç­‰å¾…ä¸­... ({i}s)")
            time.sleep(1)

        return False

    def create_service_script(self, service_name, config):
        """åˆ›å»ºæœåŠ¡å¯åŠ¨è„šæœ¬"""
        script_content = ""

        if service_name == "rag":
            script_content = self.get_rag_service_script(config)
        elif service_name == "memory":
            script_content = self.get_memory_service_script(config)
        elif service_name == "mcp-rag":
            script_content = self.get_mcp_rag_service_script(config)
        elif service_name == "mcp-memory":
            script_content = self.get_mcp_memory_service_script(config)
        elif service_name == "viz":
            script_content = self.get_viz_service_script(config)
        else:
            raise ValueError(f"æœªçŸ¥æœåŠ¡ç±»å‹: {service_name}")

        script_file = self.services_dir / f"{service_name}.py"
        with open(script_file, "w") as f:
            f.write(script_content)

        os.chmod(script_file, 0o755)
        print(f"âœ“ åˆ›å»ºæœåŠ¡è„šæœ¬: {script_file}")

    def get_rag_service_script(self, config):
        """è·å–RAGæœåŠ¡è„šæœ¬ - æ”¹è¿›ç‰ˆæœ¬"""
        return f"""#!/usr/bin/env python3
import os
import asyncio
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

# å°è¯•å¯¼å…¥LightRAG
try:
    from lightrag import LightRAG, QueryParam
    from lightrag.llm import openai_complete_if_cache, openai_embedding
    from lightrag.utils import EmbeddingFunc
    LIGHTRAG_AVAILABLE = True
except ImportError:
    LIGHTRAG_AVAILABLE = False
    print("âš ï¸ LightRAGä¸å¯ç”¨")

# å°è¯•å¯¼å…¥æœ¬åœ°æ¨¡å‹
try:
    from sentence_transformers import SentenceTransformer
    LOCAL_EMBEDDING_AVAILABLE = True
except ImportError:
    LOCAL_EMBEDDING_AVAILABLE = False
    print("âš ï¸ æœ¬åœ°Embeddingæ¨¡å‹ä¸å¯ç”¨")

app = FastAPI(title="RAG Service - Persistent Config", version="2.0.0")

# é…ç½®
WORKING_DIR = "{config.get('working_dir', './data/rag_storage')}"
PORT = {config['port']}
USE_LOCAL_EMBEDDING = os.getenv(
    'ENABLE_LOCAL_MODELS', 'true').lower() == 'true'

os.makedirs(WORKING_DIR, exist_ok=True)

# åˆå§‹åŒ–Embeddingå‡½æ•°
def get_embedding_func():
    if USE_LOCAL_EMBEDDING and LOCAL_EMBEDDING_AVAILABLE:
        try:
            print("ğŸ”„ åŠ è½½Qwen3-Embedding-0.6Bæœ¬åœ°æ¨¡å‹...")
            model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B')

            def local_embedding(texts):
                if isinstance(texts, str):
                    texts = [texts]
                embeddings = model.encode(texts)
                return embeddings.tolist()

            print("âœ… Qwen3 Embeddingæ¨¡å‹åŠ è½½æˆåŠŸ")
            return EmbeddingFunc(
                embedding_dim=1024,
                max_token_size=32768,
                func=local_embedding
            )
        except Exception as e:
            print(f"âš ï¸ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°APIæ¨¡å¼: {{e}}")

    # ä½¿ç”¨APIæ¨¡å¼
    return EmbeddingFunc(
        embedding_dim=1536,
        max_token_size=8192,
        func=lambda texts: openai_embedding(
            texts, model="text-embedding-3-small")
    )

# åˆå§‹åŒ–RAGç³»ç»Ÿ
if LIGHTRAG_AVAILABLE:
    print("ğŸš€ ä½¿ç”¨LightRAGå¼•æ“")
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=openai_complete_if_cache,
        embedding_func=get_embedding_func(),
    )
else:
    print("âŒ é”™è¯¯: LightRAGå¼•æ“ä¸å¯ç”¨")
    rag = None

class QueryRequest(BaseModel):
    query: str
    mode: str = "hybrid"

class InsertRequest(BaseModel):
    text: str

@app.get("/health")
async def health_check():
    embedding_type = "Qwen3-Local" if USE_LOCAL_EMBEDDING and LOCAL_EMBEDDING_AVAILABLE else "API"
    return {{
        "status": "healthy",
        "service": "rag-persistent",
        "engine": "lightrag" if LIGHTRAG_AVAILABLE else "none",
        "embedding": embedding_type,
        "memory_config": "{config.get('memory_limit', 'N/A')}",
        "api_key_configured": bool(os.getenv('OPENAI_API_KEY')),
        "working_dir": WORKING_DIR
    }}

@app.post("/api/query")
async def query_documents(request: QueryRequest):
    if not rag:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")

    try:
        result = await asyncio.get_event_loop().run_in_executor(
            None, lambda: rag.query(
                request.query, param=QueryParam(mode=request.mode))
        )

        return {{"status": "success", "data": result, "mode": request.mode}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/insert")
async def insert_document(request: InsertRequest):
    if not rag:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")

    try:
        await asyncio.get_event_loop().run_in_executor(
            None, lambda: rag.insert(request.text)
        )

        return {{"status": "success", "message": "æ–‡æ¡£æ’å…¥æˆåŠŸ"}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print(f"ğŸš€ å¯åŠ¨RAGæœåŠ¡ - ç«¯å£: {{PORT}}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {{WORKING_DIR}}")
    print(f"ğŸ”‘ APIå¯†é’¥: {{'å·²é…ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªé…ç½®'}}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
"""

    def get_memory_service_script(self, config):
        """è·å–MemoryæœåŠ¡è„šæœ¬ - å®Œæ•´APIç‰ˆæœ¬"""
        return f'''#!/usr/bin/env python3
import os
import sys
from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel
import uvicorn
from typing import List, Optional, Dict, Any

print("ğŸ§  å¯åŠ¨å®Œæ•´Memory APIæœåŠ¡")

# å¯¼å…¥mem0
try:
    from mem0 import Memory
    print("âœ… mem0 Memoryç±»å¯¼å…¥æˆåŠŸ")
    MEM0_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ mem0å¯¼å…¥å¤±è´¥: {{e}}")
    print("å°†ä½¿ç”¨æ¨¡æ‹ŸMemoryæœåŠ¡")
    MEM0_AVAILABLE = False

# é…ç½®
PORT = {config['port']}
print(f"ğŸ“ ç«¯å£: {{PORT}}")

# æ£€æŸ¥APIå¯†é’¥
api_key = os.getenv('OPENAI_API_KEY')
if not api_key or api_key == 'your_openai_api_key_here':
    print("âŒ é”™è¯¯: OPENAI_API_KEYæœªè®¾ç½®")
    if MEM0_AVAILABLE:
        print("ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­è¿è¡Œ...")
else:
    print(f"âœ… APIå¯†é’¥å·²é…ç½®: {{api_key[:10]}}...")

# åˆå§‹åŒ–Memoryå®ä¾‹
memory_instances = {{}}

def get_memory_instance(user_id: str = "default_user"):
    """è·å–æˆ–åˆ›å»ºç”¨æˆ·çš„Memoryå®ä¾‹"""
    if user_id not in memory_instances:
        if MEM0_AVAILABLE:
            try:
                if api_key and api_key != 'your_openai_api_key_here':
                    # ä½¿ç”¨OpenAIé…ç½®
                    config = {{
                        "llm": {{
                            "provider": "openai",
                            "config": {{
                                "model": "gpt-4o-mini",
                                "api_key": api_key,
                            }}
                        }},
                        "embedder": {{
                            "provider": "openai",
                            "config": {{
                                "model": "text-embedding-3-small",
                                "api_key": api_key,
                            }}
                        }}
                    }}
                    memory_instances[user_id] = Memory.from_config(config)
                    print(f"âœ… ä¸ºç”¨æˆ· {{user_id}} åˆ›å»ºäº†é…ç½®åŒ–Memoryå®ä¾‹")
                else:
                    # ä½¿ç”¨é»˜è®¤é…ç½®
                    memory_instances[user_id] = Memory()
                    print(f"âœ… ä¸ºç”¨æˆ· {{user_id}} åˆ›å»ºäº†é»˜è®¤Memoryå®ä¾‹")
            except Exception as e:
                print(f"âŒ Memoryå®ä¾‹åˆ›å»ºå¤±è´¥: {{e}}")
                memory_instances[user_id] = MockMemory(user_id)
        else:
            memory_instances[user_id] = MockMemory(user_id)

    return memory_instances[user_id]

# æ¨¡æ‹ŸMemoryç±»
class MockMemory:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.memories = []
        print(f"âš ï¸ ä¸ºç”¨æˆ· {{user_id}} åˆ›å»ºæ¨¡æ‹ŸMemoryæœåŠ¡")

    def add(self, text: str, **kwargs):
        memory_id = f"{{self.user_id}}_{{len(self.memories)}}"
        memory_item = {{
            "id": memory_id,
            "text": text,
            "user_id": self.user_id,
            "created_at": "2025-01-01T00:00:00Z"
        }}
        self.memories.append(memory_item)
        return {{"id": memory_id, "message": "Memory added successfully"}}

    def search(self, query: str, limit: int = 10, **kwargs):
        # ç®€å•çš„æ–‡æœ¬åŒ¹é…æœç´¢
        results = []
        for memory in self.memories:
            if query.lower() in memory["text"].lower():
                results.append({{
                    "id": memory["id"],
                    "text": memory["text"],
                    "score": 0.9,  # æ¨¡æ‹Ÿç›¸ä¼¼åº¦åˆ†æ•°
                    "created_at": memory["created_at"]
                }})
        return results[:limit]

    def get_all(self, **kwargs):
        return self.memories

    def delete(self, memory_id: str, **kwargs):
        self.memories = [m for m in self.memories if m["id"] != memory_id]
        return {{"message": f"Memory {{memory_id}} deleted"}}

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Memory API Service",
    version="1.0.0",
    description="åŸºäºmem0çš„è®°å¿†ç®¡ç†APIæœåŠ¡"
)

class AddMemoryRequest(BaseModel):
    text: str
    user_id: str = "default_user"
    metadata: Optional[Dict[str, Any]] = None

@app.get("/")
async def root():
    return {{
        "message": "Memory API Service",
        "version": "1.0.0",
        "status": "running",
        "mem0_available": MEM0_AVAILABLE
    }}

@app.get("/health")
async def health_check():
    return {{
        "status": "healthy",
        "service": "memory-api",
        "port": PORT,
        "mem0_available": MEM0_AVAILABLE,
        "api_configured": bool(api_key and api_key != 'your_openai_api_key_here'),
        "active_users": len(memory_instances)
    }}

@app.post("/memories")
async def add_memory(request: AddMemoryRequest):
    try:
        memory = get_memory_instance(request.user_id)

        if MEM0_AVAILABLE:
            result = memory.add(
                request.text,
                user_id=request.user_id,
                metadata=request.metadata
            )
        else:
            result = memory.add(request.text)

        return {{"status": "success", "data": result}}
    except Exception as e:
        print(f"æ·»åŠ è®°å¿†å¤±è´¥: {{e}}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memories/search")
async def search_memory(
    query: str,
    user_id: str = "default_user",
    limit: int = 10
):
    try:
        memory = get_memory_instance(user_id)

        if MEM0_AVAILABLE:
            result = memory.search(query, user_id=user_id, limit=limit)
        else:
            result = memory.search(query, limit=limit)

        return {{"status": "success", "data": result}}
    except Exception as e:
        print(f"æœç´¢è®°å¿†å¤±è´¥: {{e}}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memories")
async def get_all_memories(user_id: str = "default_user"):
    try:
        memory = get_memory_instance(user_id)

        if MEM0_AVAILABLE:
            result = memory.get_all(user_id=user_id)
        else:
            result = memory.get_all()

        return {{"status": "success", "data": result}}
    except Exception as e:
        print(f"è·å–è®°å¿†å¤±è´¥: {{e}}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/memories/{{memory_id}}")
async def delete_memory(memory_id: str, user_id: str = "default_user"):
    try:
        memory = get_memory_instance(user_id)

        if hasattr(memory, 'delete'):
            result = memory.delete(memory_id, user_id=user_id)
        else:
            result = {{"message": f"Memory {{memory_id}} deletion requested"}}

        return {{"status": "success", "data": result}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/users")
async def list_users():
    """åˆ—å‡ºæ‰€æœ‰æ´»è·ƒç”¨æˆ·"""
    return {{
        "status": "success",
        "data": {{
            "active_users": list(memory_instances.keys()),
            "total_users": len(memory_instances)
        }}
    }}

if __name__ == "__main__":
    print(f"ğŸš€ Memory APIæœåŠ¡å¯åŠ¨ - ç«¯å£: {{PORT}}")
    print(f"ğŸ“ Mem0çŠ¶æ€: {{'å·²è¿æ¥' if MEM0_AVAILABLE else 'æ¨¡æ‹Ÿæ¨¡å¼'}}")
    print(
        f"ğŸ”‘ APIé…ç½®: {{'å·²é…ç½®' if api_key and api_key != 'your_openai_api_key_here' else 'ä½¿ç”¨é»˜è®¤'}}")
    print(f"ğŸ“š è®¿é—®æ–‡æ¡£: http://localhost:{{PORT}}/docs")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
'''

    def get_mcp_rag_service_script(self, config):
        """è·å–MCP RAGæœåŠ¡è„šæœ¬ - ä¿®å¤ç‰ˆæœ¬"""
        return f"""#!/usr/bin/env python3
from fastapi import FastAPI, HTTPException
import httpx
import uvicorn
from typing import Any, Dict, List
            from pydantic import BaseModel

app = FastAPI(title="MCP RAG Expert - Fixed Version", version="2.0.0")

RAG_SERVICE_URL = "{config.get('target_service', 'http://localhost:8001')}"
PORT = {config['port']}

class MCPRequest(BaseModel):
    tool: str
    arguments: Dict[str, Any]

@app.get("/health")
async def health_check():
    return {{
        "status": "healthy", 
        "service": "mcp-rag-expert",
        "target": RAG_SERVICE_URL,
        "tools": {config.get('tools', [])},
        "api_key_configured": bool(os.getenv('OPENAI_API_KEY'))
    }}

@app.post("/mcp/call")
async def call_tool(request: MCPRequest):
    async with httpx.AsyncClient() as client:
        try:
            if request.tool == "hybrid_search":
                response = await client.post(f"{{RAG_SERVICE_URL}}/api/query", json=request.arguments)
                return {{"content": [{{"type": "text", "text": str(response.json())}}]}}
            elif request.tool == "insert_document":
                response = await client.post(f"{{RAG_SERVICE_URL}}/api/insert", json=request.arguments)
                return {{"content": [{{"type": "text", "text": str(response.json())}}]}}
            else:
                raise HTTPException(status_code=400, detail=f"æœªçŸ¥å·¥å…·: {{request.tool}}")
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print(f"ğŸ”Œ å¯åŠ¨MCP RAGä¸“å®¶æœåŠ¡å™¨ - ç«¯å£: {{PORT}}")
    print(f"ğŸ¯ ç›®æ ‡æœåŠ¡: {{RAG_SERVICE_URL}}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
"""

    def get_mcp_memory_service_script(self, config):
        """è·å–MCP MemoryæœåŠ¡è„šæœ¬ - ä¿®å¤ç‰ˆæœ¬"""
        return f"""#!/usr/bin/env python3
from fastapi import FastAPI, HTTPException
import httpx
import uvicorn
from typing import Any, Dict, List
from pydantic import BaseModel

app = FastAPI(title="MCP Memory Expert - Fixed Version", version="2.0.0")

MEMORY_SERVICE_URL = "{config.get('target_service', 'http://localhost:8765')}"
PORT = {config['port']}

class MCPRequest(BaseModel):
    tool: str
    arguments: Dict[str, Any]

@app.get("/health")
async def health_check():
    return {{
        "status": "healthy", 
        "service": "mcp-memory-expert",
        "target": MEMORY_SERVICE_URL,
        "tools": {config.get('tools', [])},
        "api_key_configured": bool(os.getenv('OPENAI_API_KEY'))
    }}

@app.post("/mcp/call")
async def call_tool(request: MCPRequest):
    async with httpx.AsyncClient() as client:
        try:
            if request.tool == "add_memories":
                response = await client.post(f"{{MEMORY_SERVICE_URL}}/memories", json=request.arguments)
                return {{"content": [{{"type": "text", "text": str(response.json())}}]}}
            elif request.tool == "search_memory":
                response = await client.get(f"{{MEMORY_SERVICE_URL}}/memories/search", params=request.arguments)
                return {{"content": [{{"type": "text", "text": str(response.json())}}]}}
            else:
                raise HTTPException(status_code=400, detail=f"æœªçŸ¥å·¥å…·: {{request.tool}}")
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print(f"ğŸ§  å¯åŠ¨MCPè®°å¿†ä¸“å®¶æœåŠ¡å™¨ - ç«¯å£: {{PORT}}")
    print(f"ğŸ¯ ç›®æ ‡æœåŠ¡: {{MEMORY_SERVICE_URL}}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
"""

    def get_viz_service_script(self, config):
        """è·å–å¯è§†åŒ–æœåŠ¡è„šæœ¬"""
        return f'''#!/usr/bin/env python3
from flask import Flask, render_template_string, jsonify
import json

app = Flask(__name__)
PORT = {config['port']}

@app.route("/health")
def health_check():
    return jsonify({{"status": "healthy", "service": "viz-fixed", "port": PORT}})

@app.route("/")
def index():
    return """
    <h1>ğŸ¨ çŸ¥è¯†å›¾è°±å¯è§†åŒ–æœåŠ¡</h1>
    <p><strong>ç«¯å£:</strong> {config['port']}</p>
    <p><strong>çŠ¶æ€:</strong> è¿è¡Œä¸­</p>
    <p><strong>é…ç½®:</strong> æŒä¹…åŒ–ç‰ˆæœ¬</p>
    """

if __name__ == "__main__":
    print(f"ğŸ¨ å¯åŠ¨å¯è§†åŒ–æœåŠ¡ - ç«¯å£: {{PORT}}")
    app.run(host="0.0.0.0", port=PORT, debug=False)
'''

    def list_services(self):
        """åˆ—å‡ºæ‰€æœ‰æœåŠ¡"""
        print("ğŸš€ AIçŸ¥è¯†ç®¡ç†ç³»ç»ŸæœåŠ¡çŠ¶æ€ (æŒä¹…åŒ–ç‰ˆæœ¬)")
        print("=" * 120)
        print(
            f"{'æœåŠ¡å':<15} {'çŠ¶æ€':<12} {'PID':<8} {'ç«¯å£':<6} {'å†…å­˜(MB)':<10} {'CPU%':<6} {'å¯åŠ¨æ—¶é—´':<20} {'æè¿°':<25}"
        )
        print("=" * 120)

        # æ›´æ–°æœåŠ¡åˆ—è¡¨ï¼ŒåŒ…å«ä¸¤ä¸ªMCPæœåŠ¡å™¨
        all_services = ["rag", "memory", "mcp-rag", "mcp-memory", "viz"]

        for service_name in all_services:
            if service_name in self.state["services"]:
                service_info = self.state["services"][service_name]
                pid = service_info["pid"]
                port = service_info["port"]
                started_at = (
                    service_info["started_at"][:19]
                    if service_info.get("started_at")
                    else "N/A"
                )
                description = service_info.get("config", {}).get("description", "")[:25]

                if psutil.pid_exists(pid):
                    try:
                        process = psutil.Process(pid)
                        memory = round(process.memory_info().rss / 1024 / 1024, 1)
                        cpu = round(process.cpu_percent(), 1)
                        status = "ğŸŸ¢ è¿è¡Œä¸­"
                    except:
                        memory = 0
                        cpu = 0
                        status = "ğŸ”´ é”™è¯¯"
                else:
                    memory = 0
                    cpu = 0
                    status = "ğŸ”´ å·²åœæ­¢"
                    # æ¸…ç†å·²åœæ­¢çš„æœåŠ¡
                    del self.state["services"][service_name]
                    self.save_state()

                print(
                    f"{service_name:<15} {status:<12} {pid:<8} {port:<6} {memory:<10} {cpu:<6} {started_at:<20} {description:<25}"
                )
            else:
                print(
                    f"{service_name:<15} {'âšª æœªå¯åŠ¨':<12} {'N/A':<8} {'N/A':<6} {'0':<10} {'0':<6} {'N/A':<20} {'N/A':<25}"
                )

    def get_system_status(self):
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        # ç³»ç»Ÿæ€»ä½“çŠ¶æ€
        memory = psutil.virtual_memory()
        cpu = psutil.cpu_percent(interval=1)

        print("\\nğŸ’» ç³»ç»Ÿèµ„æºçŠ¶æ€:")
        print("-" * 60)
        print(f"æ€»å†…å­˜: {memory.total // 1024 // 1024 // 1024}GB")
        print(f"å·²ç”¨å†…å­˜: {memory.used // 1024 // 1024}MB ({memory.percent:.1f}%)")
        print(f"å¯ç”¨å†…å­˜: {memory.available // 1024 // 1024}MB")
        print(f"CPUä½¿ç”¨ç‡: {cpu:.1f}%")

        # äº¤æ¢ç©ºé—´
        swap = psutil.swap_memory()
        if swap.total > 0:
            print(
                f"äº¤æ¢ç©ºé—´: {swap.used // 1024 // 1024}MB / {swap.total // 1024 // 1024}MB ({swap.percent:.1f}%)"
            )

        # å†…å­˜ä½¿ç”¨å»ºè®®
        if memory.percent > 85:
            print("âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®åœæ­¢éƒ¨åˆ†æœåŠ¡")
        elif memory.percent < 60:
            print("âœ… å†…å­˜ä½¿ç”¨ç‡æ­£å¸¸ï¼Œå¯ä»¥å¯åŠ¨æ›´å¤šæœåŠ¡")
        else:
            print("ğŸ”„ å†…å­˜ä½¿ç”¨ç‡é€‚ä¸­")


def main():
    parser = argparse.ArgumentParser(
        description="AIçŸ¥è¯†ç®¡ç†ç³»ç»ŸæœåŠ¡ç®¡ç†å™¨ - æŒä¹…åŒ–ç‰ˆæœ¬"
    )
    parser.add_argument(
        "action", choices=["start", "stop", "restart", "list", "status"]
    )
    parser.add_argument(
        "--service",
        help="æœåŠ¡åç§° (rag, memory, mcp-rag, mcp-memory, viz, core, mcp, all)",
    )

    args = parser.parse_args()
    manager = ServiceManager()

    if args.action == "start":
        if args.service == "all":
            # æŒ‰ä¾èµ–é¡ºåºå¯åŠ¨ï¼šå…ˆå¯åŠ¨åŸºç¡€æœåŠ¡ï¼Œå†å¯åŠ¨MCPæœåŠ¡
            services = ["rag", "memory", "mcp-rag", "mcp-memory", "viz"]
            print("ğŸš€ å¯åŠ¨æ‰€æœ‰æœåŠ¡...")
            for service in services:
                manager.start_service(service)
                time.sleep(3)  # é—´éš”å¯åŠ¨é¿å…èµ„æºå†²çª
        elif args.service == "core":
            # åªå¯åŠ¨æ ¸å¿ƒæœåŠ¡ï¼ˆèŠ‚çœå†…å­˜ï¼‰
            services = ["rag", "memory"]
            print("ğŸ¯ å¯åŠ¨æ ¸å¿ƒæœåŠ¡...")
            for service in services:
                manager.start_service(service)
                time.sleep(3)
        elif args.service == "mcp":
            # å¯åŠ¨æ‰€æœ‰MCPæœåŠ¡
            services = ["mcp-rag", "mcp-memory"]
            print("ğŸ”Œ å¯åŠ¨MCPä¸“å®¶æœåŠ¡å™¨...")
            for service in services:
                manager.start_service(service)
                time.sleep(2)
        elif args.service:
            manager.start_service(args.service)
        else:
            print(
                "è¯·æŒ‡å®šè¦å¯åŠ¨çš„æœåŠ¡: rag, memory, mcp-rag, mcp-memory, viz, core, mcp, all"
            )

    elif args.action == "stop":
        if args.service == "all":
            services = ["viz", "mcp-memory", "mcp-rag", "memory", "rag"]  # åå‘åœæ­¢
            print("ğŸ›‘ åœæ­¢æ‰€æœ‰æœåŠ¡...")
            for service in services:
                if manager.is_service_running(service):
                    manager.stop_service(service)
        elif args.service == "mcp":
            services = ["mcp-rag", "mcp-memory"]
            for service in services:
                if manager.is_service_running(service):
                    manager.stop_service(service)
        elif args.service:
            manager.stop_service(args.service)
        else:
            print("è¯·æŒ‡å®šè¦åœæ­¢çš„æœåŠ¡")

    elif args.action == "restart":
        if args.service:
            print(f"ğŸ”„ é‡å¯æœåŠ¡: {args.service}")
            manager.stop_service(args.service)
            time.sleep(3)
            manager.start_service(args.service)
        else:
            print("è¯·æŒ‡å®šè¦é‡å¯çš„æœåŠ¡")

    elif args.action == "list":
        manager.list_services()

    elif args.action == "status":
        manager.list_services()
        manager.get_system_status()


if __name__ == "__main__":
    main()
