#!/usr/bin/env python3
import os
import time
import asyncio
from datetime import datetime
from fastapi import FastAPI, HTTPException
from contextlib import asynccontextmanager

from pydantic import BaseModel
import uvicorn

# å°è¯•å¯¼å…¥RAG-Anything (ä¼˜å…ˆ)
try:
    from raganything import RAGAnything, RAGAnythingConfig
    RAG_ANYTHING_AVAILABLE = True
    print("âœ… RAG-Anythingå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    RAG_ANYTHING_AVAILABLE = False
    print(f"âš ï¸ RAG-Anythingä¸å¯ç”¨: {e}")

# å¤‡ç”¨å¯¼å…¥LightRAG
try:
    from lightrag import LightRAG, QueryParam
    from lightrag.llm.openai import openai_complete_if_cache
    from lightrag.utils import EmbeddingFunc
    LIGHTRAG_AVAILABLE = True
    print("âœ… LightRAGå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    LIGHTRAG_AVAILABLE = False
    print(f"âš ï¸ LightRAGä¸å¯ç”¨: {e}")

# å°è¯•å¯¼å…¥æœ¬åœ°æ¨¡å‹
try:
    from sentence_transformers import SentenceTransformer
    LOCAL_EMBEDDING_AVAILABLE = True
    print("âœ… æœ¬åœ°Embeddingæ¨¡å‹å¯ç”¨")
except ImportError:
    LOCAL_EMBEDDING_AVAILABLE = False
    print("âš ï¸ æœ¬åœ°Embeddingæ¨¡å‹ä¸å¯ç”¨")



# é…ç½®
WORKING_DIR = os.getenv('RAG_WORKING_DIR', './rag_storage')
PORT = 8001

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL', 'Qwen/Qwen3-Embedding-0.6B')
EMBEDDING_MODEL_TYPE = os.getenv('EMBEDDING_MODEL_TYPE', 'local').strip()
OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.deepseek.com/v1')
USE_LOCAL_EMBEDDING = EMBEDDING_MODEL_TYPE.lower() == 'local'

print(f"ğŸ”§ é…ç½®ä¿¡æ¯:")
print(f"  - Embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
print(f"  - æ¨¡å‹ç±»å‹: {EMBEDDING_MODEL_TYPE}")
print(f"  - API Base URL: {OPENAI_BASE_URL}")
print(f"  - ä½¿ç”¨æœ¬åœ°Embedding: {USE_LOCAL_EMBEDDING}")

os.makedirs(WORKING_DIR, exist_ok=True)

# ğŸ¯ å…¨å±€embeddingæ¨¡å‹å®ä¾‹ - åœ¨æœåŠ¡å¯åŠ¨æ—¶é¢„åŠ è½½
_global_embedding_model = None
_embedding_model_loaded = False

# é¢„åŠ è½½embeddingæ¨¡å‹
async def load_embedding_model():
    """é¢„åŠ è½½embeddingæ¨¡å‹åˆ°å…¨å±€å˜é‡"""
    global _global_embedding_model, _embedding_model_loaded
    
    if _embedding_model_loaded:
        print("âœ… Embeddingæ¨¡å‹å·²é¢„åŠ è½½")
        return
        
    if USE_LOCAL_EMBEDDING and LOCAL_EMBEDDING_AVAILABLE:
        try:
            print(f"ğŸ”„ é¢„åŠ è½½æœ¬åœ°embeddingæ¨¡å‹: {EMBEDDING_MODEL}...")
            _global_embedding_model = SentenceTransformer(EMBEDDING_MODEL)
            _embedding_model_loaded = True
            print("âœ… Qwen3-Embeddingæ¨¡å‹é¢„åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            print(f"âš ï¸ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            _embedding_model_loaded = False
    else:
        print("ğŸ”§ ä½¿ç”¨API embeddingæ¨¡å¼ï¼Œæ— éœ€é¢„åŠ è½½æ¨¡å‹")
        _embedding_model_loaded = True

async def global_embedding_func(texts):
    """ä½¿ç”¨å…¨å±€é¢„åŠ è½½çš„embeddingæ¨¡å‹"""
    global _global_embedding_model
    
    if isinstance(texts, str):
        texts = [texts]
    
    if _global_embedding_model is not None:
        # ä½¿ç”¨é¢„åŠ è½½çš„æœ¬åœ°æ¨¡å‹
        embeddings = _global_embedding_model.encode(
            texts, 
            normalize_embeddings=True, 
            show_progress_bar=False
        )
        return embeddings.tolist()
    else:
        # å›é€€åˆ°APIæ¨¡å¼ - ä½¿ç”¨ç®€å•çš„è¿”å›ï¼Œå®é™…ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
        print("âš ï¸ è­¦å‘Š: å…¨å±€embeddingå‡½æ•°å›é€€åˆ°APIæ¨¡å¼")
        return [[0.0] * 1536 for _ in texts]  # è¿”å›dummy embeddings

# åˆå§‹åŒ–Embeddingå‡½æ•°
def get_embedding_func():
    if USE_LOCAL_EMBEDDING and LOCAL_EMBEDDING_AVAILABLE:
        return EmbeddingFunc(
            embedding_dim=1024,
            max_token_size=32768,
            func=global_embedding_func
        )
    else:
        # APIæ¨¡å¼æš‚ä¸æ”¯æŒï¼Œè¿”å›dummyå‡½æ•°
        print("âš ï¸ API embeddingæ¨¡å¼æš‚ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
        async def dummy_embedding_func(texts):
            if isinstance(texts, str):
                texts = [texts]
            return [[0.0] * 1536 for _ in texts]
        
        return EmbeddingFunc(
            embedding_dim=1536,
            max_token_size=8192,
            func=dummy_embedding_func
        )

# åˆ›å»ºLLMå‡½æ•°ï¼ˆæ”¯æŒDeepSeekï¼‰
def create_llm_func():
    """åˆ›å»ºæ”¯æŒDeepSeekçš„LLMå‡½æ•°"""
    try:
        from lightrag.llm.openai import openai_complete_if_cache
        
        # ä½¿ç”¨DeepSeek API
        def deepseek_llm_func(prompt, system_prompt=None, history_messages=[], **kwargs):
            return openai_complete_if_cache(
                model="deepseek-chat",
                prompt=prompt,
                system_prompt=system_prompt, 
                history_messages=history_messages,
                base_url=OPENAI_BASE_URL,
                **kwargs
            )
        return deepseek_llm_func
    except Exception as e:
        print(f"âš ï¸ åˆ›å»ºLLMå‡½æ•°å¤±è´¥: {e}")
        return None

# åˆå§‹åŒ–RAGç³»ç»Ÿ
rag = None

# ä¼˜å…ˆä½¿ç”¨RAG-Anythingï¼ˆæ›´å…ˆè¿›çš„æ–‡æ¡£å¤„ç†èƒ½åŠ›ï¼‰
if RAG_ANYTHING_AVAILABLE:
    try:
        print("ğŸš€ ä½¿ç”¨RAG-Anythingå¼•æ“åˆå§‹åŒ–...")
        
        # åˆ›å»ºå¿…è¦çš„å‡½æ•°
        llm_func = create_llm_func()
        embedding_func = get_embedding_func()
        
        if llm_func and embedding_func:
            # åˆ›å»ºRAG-Anythingé…ç½®
            config = RAGAnythingConfig(
                working_dir=WORKING_DIR,
                display_content_stats=True,
                enable_image_processing=True,
                enable_table_processing=True,
                max_concurrent_files=1,
                max_context_tokens=2000
            )
            
            # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åˆ›å»ºRAG-Anything
            rag = RAGAnything(
                config=config,
                llm_model_func=llm_func,
                vision_model_func=llm_func,  # ä½¿ç”¨åŒä¸€ä¸ªLLMå‡½æ•°ä½œä¸ºè§†è§‰æ¨¡å‹
                embedding_func=embedding_func,
            )
            print("âœ… RAG-Anythingå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âŒ LLMæˆ–embeddingå‡½æ•°åˆ›å»ºå¤±è´¥ï¼Œæ— æ³•åˆå§‹åŒ–RAG-Anything")
            rag = None
    except Exception as e:
        print(f"âŒ RAG-Anythingåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        rag = None

# å¤‡ç”¨LightRAGï¼ˆå¦‚æœRAG-Anythingå¤±è´¥ï¼‰
if rag is None and LIGHTRAG_AVAILABLE:
    try:
        print("ğŸš€ å›é€€åˆ°LightRAGå¼•æ“...")
        llm_func = create_llm_func()
        if llm_func:
            rag = LightRAG(
                working_dir=WORKING_DIR,
                llm_model_func=llm_func,
                embedding_func=get_embedding_func(),
            )
            print("âœ… LightRAGå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âŒ LLMå‡½æ•°åˆ›å»ºå¤±è´¥")
    except Exception as e:
        print(f"âŒ LightRAGåˆå§‹åŒ–å¤±è´¥: {e}")
        rag = None

if rag is None:
    print("âŒ æ²¡æœ‰å¯ç”¨çš„RAGå¼•æ“")
    rag = None

# å…¨å±€è¿›åº¦å­˜å‚¨
file_progress = {}

class QueryRequest(BaseModel):
    query: str
    mode: str = "hybrid"

class InsertRequest(BaseModel):
    text: str

class ParseDocumentRequest(BaseModel):
    file_path: str
    knowledge_base: str = "default"
    parse_method: str = "auto"
    output_dir: str = None
    display_stats: bool = True

# æ·»åŠ æœåŠ¡å¯åŠ¨äº‹ä»¶
#@app.on_event("startup")

# æ·»åŠ  lifespan ç®¡ç†å™¨
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶çš„åˆå§‹åŒ–
    print("ğŸš€ RAGæœåŠ¡å¯åŠ¨ä¸­...")
    await load_embedding_model()
    print("âœ… RAGæœåŠ¡å¯åŠ¨å®Œæˆ!")
    
    yield  # åº”ç”¨è¿è¡ŒæœŸé—´
    
    # å…³é—­æ—¶çš„æ¸…ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
    print("ğŸ”„ RAGæœåŠ¡å…³é—­ä¸­...")
# åˆ›å»ºFastAPIåº”ç”¨ï¼Œä½¿ç”¨lifespan
app = FastAPI(
    title="RAG Service - RAG-Anything Edition", 
    version="2.1.0",
    lifespan=lifespan
)


@app.get("/api/progress/{file_key}")
async def get_file_progress(file_key: str):
    """è·å–æ–‡ä»¶å¤„ç†è¿›åº¦"""
    if file_key in file_progress:
        return file_progress[file_key]
    else:
        return {"progress": 0, "message": "æœªæ‰¾åˆ°æ–‡ä»¶å¤„ç†è®°å½•"}

@app.get("/health")
async def health_check():
    embedding_type = "Qwen3-Local-Preloaded" if USE_LOCAL_EMBEDDING and _embedding_model_loaded else "API"
    engine_type = "none"
    if rag:
        if RAG_ANYTHING_AVAILABLE and isinstance(rag, RAGAnything):
            engine_type = "rag-anything"
        elif LIGHTRAG_AVAILABLE:
            engine_type = "lightrag"
    
    # ğŸ¯ æ–°å¢ï¼šæ£€æŸ¥ MineruParser ä¿®å¤çŠ¶æ€
    mineru_fix_status = "unknown"
    mineru_fix_info = {}
    
    try:
        from raganything.mineru_parser import MineruParser, MINERU_PARSER_VERSION, MINERU_PARSER_FIX_INFO
        
        # éªŒè¯ä¿®å¤æ˜¯å¦ç”Ÿæ•ˆ
        if MineruParser.verify_fix_active():
            mineru_fix_status = "active"
            mineru_fix_info = MineruParser.get_fix_info()
            print(f"ğŸ”§ MineruParser ä¿®å¤çŠ¶æ€: {mineru_fix_status}")
            print(f"ğŸ”§ ä¿®å¤ç‰ˆæœ¬: {MINERU_PARSER_VERSION}")
        else:
            mineru_fix_status = "inactive"
            
    except Exception as e:
        mineru_fix_status = "error"
        mineru_fix_info = {"error": str(e)}
        print(f"âŒ MineruParser ä¿®å¤çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
    return {
        "status": "healthy", 
        "service": "rag-persistent",
        "engine": engine_type,
        "embedding": embedding_type,
        "embedding_model_preloaded": _embedding_model_loaded,
        "embedding_model_name": EMBEDDING_MODEL,
        "memory_config": "4.5GB",
        "api_key_configured": bool(os.getenv('OPENAI_API_KEY')),
        "working_dir": WORKING_DIR,
        "rag_available": rag is not None,
        
        # ğŸ¯ æ–°å¢ä¿®å¤çŠ¶æ€ä¿¡æ¯
        "mineru_parser_fix": {
            "status": mineru_fix_status,
            "info": mineru_fix_info,
            "timestamp": datetime.now().isoformat()
        }
    }

# ğŸ¯ æ–°å¢ï¼šä¸“é—¨çš„ä¿®å¤çŠ¶æ€æ£€æŸ¥æ¥å£
@app.get("/api/mineru-fix-status")
async def check_mineru_fix_status():
    """ä¸“é—¨æ£€æŸ¥ MineruParser ä¿®å¤çŠ¶æ€çš„æ¥å£"""
    
    try:
        from raganything.mineru_parser import MineruParser, MINERU_PARSER_VERSION, MINERU_PARSER_FIX_INFO
        
        # è·å–è¯¦ç»†çš„ä¿®å¤ä¿¡æ¯
        fix_info = MineruParser.get_fix_info()
        is_active = MineruParser.verify_fix_active()
        
        # æ£€æŸ¥æ–¹æ³•ç­¾å
        import inspect
        sig = inspect.signature(MineruParser._run_mineru_command)
        has_progress_callback = 'progress_callback' in sig.parameters
        
        return {
            "status": "success",
            "fix_active": is_active,
            "fix_version": MINERU_PARSER_VERSION,
            "fix_info": fix_info,
            "progress_callback_supported": has_progress_callback,
            "method_signature": list(sig.parameters.keys()),
            "timestamp": datetime.now().isoformat(),
            "message": "MineruParser ä¿®å¤çŠ¶æ€æ£€æŸ¥å®Œæˆ"
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "message": "MineruParser ä¿®å¤çŠ¶æ€æ£€æŸ¥å¤±è´¥",
            "timestamp": datetime.now().isoformat()
        }


@app.post("/api/query")
async def query_documents(request: QueryRequest):
    if not rag:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        if RAG_ANYTHING_AVAILABLE and isinstance(rag, RAGAnything):
            # ä½¿ç”¨RAG-Anythingçš„æŸ¥è¯¢æ–¹æ³•
            result = await asyncio.get_event_loop().run_in_executor(
                None, lambda: rag.query(request.query)
            )
        else:
            # ä½¿ç”¨LightRAGçš„æŸ¥è¯¢æ–¹æ³•
            result = await asyncio.get_event_loop().run_in_executor(
                None, lambda: rag.query(request.query, param=QueryParam(mode=request.mode))
            )
        
        return {"status": "success", "data": result, "mode": request.mode}
    except Exception as e:
        print(f"æŸ¥è¯¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/query-profile")
async def query_with_profiling(request: QueryRequest):
    """å¸¦æ€§èƒ½åˆ†æçš„æŸ¥è¯¢æ¥å£"""
    if not rag:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")
    
    import time
    import tracemalloc
    
    # å¼€å§‹å†…å­˜è¿½è¸ª
    tracemalloc.start()
    
    # è®°å½•å„é˜¶æ®µæ—¶é—´
    timings = {}
    start_total = time.time()
    
    try:
        print(f"ğŸ” å¼€å§‹æ€§èƒ½åˆ†ææŸ¥è¯¢: {request.query[:50]}...")
        
        # é˜¶æ®µ1: æŸ¥è¯¢é¢„å¤„ç†
        start_prep = time.time()
        query_text = request.query.strip()
        mode = request.mode
        timings["preprocessing"] = time.time() - start_prep
        
        # é˜¶æ®µ2: Embeddingè®¡ç®— (å¦‚æœéœ€è¦)
        start_embed = time.time()
        # è¿™é‡Œå®é™…çš„embeddingè®¡ç®—åœ¨LightRAGå†…éƒ¨è¿›è¡Œ
        timings["embedding_prep"] = time.time() - start_embed
        
        # é˜¶æ®µ3: ä¸»è¦æŸ¥è¯¢è¿‡ç¨‹
        start_query = time.time()
        
        if RAG_ANYTHING_AVAILABLE and isinstance(rag, RAGAnything):
            result = await asyncio.get_event_loop().run_in_executor(
                None, lambda: rag.query(query_text)
            )
        else:
            # åŒ…è£…æŸ¥è¯¢ä»¥è·å–æ›´è¯¦ç»†çš„æ—¶é—´ä¿¡æ¯
            def timed_query():
                inner_start = time.time()
                print(f"ğŸ“Š LightRAGæŸ¥è¯¢å¼€å§‹ - æ¨¡å¼: {mode}")
                
                result = rag.query(query_text, param=QueryParam(mode=mode))
                
                inner_duration = time.time() - inner_start
                print(f"ğŸ“Š LightRAGæŸ¥è¯¢å®Œæˆ - è€—æ—¶: {inner_duration:.2f}ç§’")
                return result
            
            result = await asyncio.get_event_loop().run_in_executor(None, timed_query)
        
        timings["main_query"] = time.time() - start_query
        
        # æ€»æ—¶é—´
        timings["total"] = time.time() - start_total
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        
        # æ€§èƒ½ç»Ÿè®¡
        performance_stats = {
            "timings": {k: round(v, 3) for k, v in timings.items()},
            "memory": {
                "current_mb": round(current / 1024 / 1024, 2),
                "peak_mb": round(peak / 1024 / 1024, 2)
            },
            "query_info": {
                "mode": mode,
                "query_length": len(query_text),
                "result_length": len(result) if result else 0
            }
        }
        
        print(f"ğŸ“Š æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡:")
        print(f"  - é¢„å¤„ç†: {timings['preprocessing']:.3f}s")
        print(f"  - ä¸»æŸ¥è¯¢: {timings['main_query']:.3f}s") 
        print(f"  - æ€»è€—æ—¶: {timings['total']:.3f}s")
        print(f"  - å†…å­˜å³°å€¼: {performance_stats['memory']['peak_mb']}MB")
        
        return {
            "status": "success",
            "data": result,
            "mode": mode,
            "performance": performance_stats
        }
        
    except Exception as e:
        tracemalloc.stop()
        print(f"æŸ¥è¯¢å¤±è´¥: {e}")
        timings["total"] = time.time() - start_total
        raise HTTPException(status_code=500, detail={
            "error": str(e),
            "timings": timings
        })

@app.post("/api/parse-document")
async def parse_document_complete(request: ParseDocumentRequest):
    """ä½¿ç”¨ RAG-Anything çš„ process_document_complete è¿›è¡Œå®Œæ•´æ–‡æ¡£å¤„ç†"""
    # ğŸ¯ è°ƒè¯•åŸ‹ç‚¹ï¼šéªŒè¯ä»£ç æ˜¯å¦åŠ è½½
    print("ğŸ”§ DEBUG: parse_document_complete è¢«è°ƒç”¨ï¼Œæµ‹è¯•ä¿®å¤ç‰ˆæœ¬åŠ è½½")
    print(f"ğŸ”§ DEBUG: è¯·æ±‚æ–‡ä»¶è·¯å¾„: {request.file_path}")
    
    if not rag:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        if RAG_ANYTHING_AVAILABLE and isinstance(rag, RAGAnything):
            print(f"ğŸ”„ å¼€å§‹å®Œæ•´æ–‡æ¡£å¤„ç†: {request.file_path}")
            
            # ç”Ÿæˆæ–‡ä»¶keyï¼ˆä½¿ç”¨æ–‡ä»¶è·¯å¾„çš„basenameï¼‰
            file_key = os.path.basename(request.file_path)
            
            # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
            async def progress_callback(progress: int, message: str):
                file_progress[file_key] = {
                    "progress": progress,
                    "message": message,
                    "file_path": request.file_path,
                    "timestamp": time.time()
                }
                print(f"ğŸ“Š å¤„ç†è¿›åº¦ [{file_key}]: {progress}% - {message}")
            
            try:
                # åˆå§‹åŒ–è¿›åº¦
                await progress_callback(0, "å‡†å¤‡å¼€å§‹æ–‡æ¡£å¤„ç†...")
                
                # ä½¿ç”¨ RAG-Anything çš„ process_document_complete ä¸è¿›åº¦å›è°ƒ
                await rag.process_document_complete(
                    file_path=request.file_path,
                    output_dir=request.output_dir,
                    parse_method=request.parse_method,
                    display_stats=request.display_stats,
                    progress_callback=progress_callback
                )
                print(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {request.file_path}")
            except Exception as e:
                await progress_callback(-1, f"å¤„ç†å¤±è´¥: {str(e)}")
                print(f"âŒ æ–‡æ¡£å¤„ç†å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                raise
            
            return {
                "status": "success", 
                "message": "æ–‡æ¡£å®Œæ•´å¤„ç†æˆåŠŸ",
                "file_path": request.file_path,
                "engine": "rag-anything"
            }
        else:
            # å›é€€åˆ°ç®€å•çš„æ–‡æœ¬æ’å…¥ï¼ˆå¦‚æœä¸æ˜¯RAG-Anythingå¼•æ“ï¼‰
            raise HTTPException(
                status_code=501, 
                detail="å®Œæ•´æ–‡æ¡£å¤„ç†éœ€è¦ RAG-Anything å¼•æ“"
            )
        
    except Exception as e:
        print(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/insert")
async def insert_document(request: InsertRequest):
    """ä¼ ç»Ÿçš„æ–‡æœ¬æ’å…¥æ¥å£ï¼Œä¿æŒå‘åå…¼å®¹"""
    if not rag:
        raise HTTPException(status_code=500, detail="RAGå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        if RAG_ANYTHING_AVAILABLE and isinstance(rag, RAGAnything):
            # ä½¿ç”¨RAG-Anythingçš„æ’å…¥æ–¹æ³•
            await asyncio.get_event_loop().run_in_executor(
                None, lambda: rag.insert(request.text)
            )
        else:
            # ä½¿ç”¨LightRAGçš„æ’å…¥æ–¹æ³•
            await asyncio.get_event_loop().run_in_executor(
                None, lambda: rag.insert(request.text)
            )
        
        return {"status": "success", "message": "æ–‡æ¡£æ’å…¥æˆåŠŸ"}
    except Exception as e:
        print(f"æ’å…¥æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print(f"ğŸš€ å¯åŠ¨RAGæœåŠ¡ - ç«¯å£: {PORT}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {WORKING_DIR}")
    print(f"ğŸ”‘ APIå¯†é’¥: {'å·²é…ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªé…ç½®'}")
    if rag:
        if RAG_ANYTHING_AVAILABLE and isinstance(rag, RAGAnything):
            print("ğŸ”§ ä½¿ç”¨å¼•æ“: RAG-Anything")
        else:
            print("ğŸ”§ ä½¿ç”¨å¼•æ“: LightRAG")
    else:
        print("âš ï¸ è­¦å‘Š: æ²¡æœ‰å¯ç”¨çš„RAGå¼•æ“")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
